#!/bin/bash
#
# this file contains the common functions for GW summary page automation
#
# Note: modified by Max Isi for the 40m (July 16, 2015)
#   - Default Kerberos credentials;
#   - Use "condor_q -wide -s" in wait_for_dag_and_exit() to make condor_q work
#     with user "40m".

# -- variables ----------------------------------------------------------------

# basic variables
[ -z "$USER" ] && USER=`whoami`
[ -z "$ACCOUNT_GROUP_USER" ] && ACCOUNT_GROUP_USER="max.isi"

# summary variables
[ -z "$_SUMMARY_OUT" ] && export _SUMMARY_OUT="${HOME}/public_html/summary"
[ -z "$_SUMMARY_REPO" ] && export _SUMMARY_REPO="${HOME}/etc/summary"
[ -z "$_SUMMARY_CONFIG" ] && export _SUMMARY_CONFIG="${_SUMMARY_REPO}/configurations"
[ -z "$_SUMMARY_NAGIOS" ] && export _SUMMARY_NAGIOS="${_SUMMARY_OUT}/nagios"
[ -z "$_SUMMARY_JOB" ] && export _SUMMARY_JOB=`basename "$0"`
[ -z "$LOGDIR" ] && LOGDIR="${_SUMMARY_OUT}/logs"

# workaround auth issues
if [ "${USER}" == "detchar" ]; then
    unset X509_USER_PROXY
fi

# set python variables
PYTHON_VERSION=$(
    python -c 'import sys; print(".".join(map(str, sys.version_info[:2])))')
GWPYSOFT_VIRTUAL_ENV="/home/detchar/opt/gwpysoft-${PYTHON_VERSION}"
GWPYSOFT_MKL_BASE="${GWPYSOFT_VIRTUAL_ENV}-mkl"

# -- environment --------------------------------------------------------------

activate_gwpysoft() {
    . ${GWPYSOFT_VIRTUAL_ENV}/bin/activate
}

activate_mkl_numpy_scipy() {
    . ${GWPYSOFT_MKL_BASE}/etc/gwpy-user-env.sh
}

# -- generic functions --------------------------------------------------------

echoerr() {
    echo "$@" 1>&2;
 }

get_exit_code() {
    eval $@
    local exitcode=$?
    echo $exitcode
    return $exitcode
}

# -- get date strings ---------------------------------------------------------

# find today's date
date_today_utc() {
    local gpstime=`lalapps_tconvert`;
    echo `lalapps_tconvert -f %Y%m%d ${gpstime}`;
    return 0;
}

alias date_today=date_today_utc

date_today_local() {
    local gpstime=`lalapps_tconvert`;
    echo `lalapps_tconvert -Lf %Y%m%d ${gpstime}`;
    return 0;
}

# find yesterday's date
date_yesterday() {
    let gpstime=`lalapps_tconvert`-86400;
    echo `lalapps_tconvert -f %Y%m%d ${gpstime}`;
    return 0;
}

# -- kerberos -----------------------------------------------------------------

# get kerberos ticket
get_robot_kerberos_ticket() {
    export KRB5CCNAME=${TMPDIR}/gw_summary_ligo.org.krb5
    export KRB5_KTNAME=${HOME}/.kerberos/40m.robot.ldas-pcdev1.ligo.caltech.edu
    if [ -f ${KRB5_KTNAME} ]; then
        local LIGO_USER="40m/robot/ldas-pcdev1.ligo.caltech.edu"
        local exitcode=`get_exit_code "kinit -kft ${KRB5_KTNAME} ${LIGO_USER}@LIGO.ORG 1> /dev/null"`
    else
        local LIGO_USER="max.isi"
        export KRB5_KTNAME=${HOME}/.kerberos/max.isi.keytab
        local exitcode=`get_exit_code "kinit -kft ${KRB5_KTNAME} ${LIGO_USER}@LIGO.ORG 1> /dev/null"`
    fi
    if [ $exitcode -eq 0 ]; then
        echo "Kerberos ticket generated for ${LIGO_USER}"
    else
        echoerr "Failed to generate kerberos ticket"
    fi
    return $exitcode
}

# check kerberos ticket
check_kerberos_ticket() {
    local exitcode=`get_exit_code klist -s`
    if [ $? -eq 1 ]; then
        echoerr "gw_summary requires a kerberos ticket, please generate one and try again"
    fi
    return $exitcode
}

# -- environment --------------------------------------------------------------

set_site_environment() {
    # get IFO variable based on hostname
    if [[ $IFO ]]; then
        true
    elif [[ "`hostname -f`" == *"ligo-la"* ]]; then
        IFO="L1"
    elif [[ "`hostname -f`" == *"ligo-wa"* ]]; then
        IFO="H1"
    elif [[ "`hostname -f`" == *"ligo.caltech"* ]]; then
        IFO="All"
    fi
    if [[ -z "${IFO}" ]]; then
        echoerr "Cannot determine IFO, either give via '--ifo=X1' of set IFO environment variable"
        return 1
    fi
    # set associated variables
    ifo=`echo $IFO | awk '{print tolower($0)}'`
    SITE=${IFO:0:1}
    site=${ifo:0:1}
}

activate_gwpysoft() {
    . ${GWPYSOFT_VIRTUAL_ENV}/bin/activate
}

deactivate_gwpysoft() {
    ${GWPYSOFT_VIRTUAL_ENV}/bin/deactivate
}

# -- git ----------------------------------------------------------------------

# refresh repository
update_summary_git() {
    local repodir=$1
    [ -z $repodir ] && local repodir=${_SUMMARY_REPO}
    if [ -d ${repodir}/.git ]; then
        cd $repodir
        timeout 10 git pull
        EC=$?
        cd - 1>/dev/null
        return $EC
    else
        echoerr "Cannot local summary git repo in $repordir"
        return 1
    fi
}

# -- argument parsing ---------------------------------------------------------

parse_argument_default() {
    local argname=$1
    shift
    local default=$@
    # test clargs param for argument
    if [[ "${_SUMMARY_ARGUMENTS}" == *"$argname"* ]]; then
        echo ""
    else
        echo --$argname $default
    fi
}

# -- configurations -----------------------------------------------------------

[ -z "$_SUMMARY_SYSTEMS" ] && _SUMMARY_SYSTEMS="
psl hoft hoft-science hoft-lines calibration pcal guardian
imc lsc lsc-darm asc omc
sei sei2 sei-quiet sei-noisy sei_watchdogs
sus sus2 sus-oplev
pem tcs
kleinewelle pycbc analysis
hveto pcat idq upv stamp fscan
detchar
"

get_fast_systems() {
    if [ -z "${_SUMMARY_SYSTEMS_FAST}" ]; then
        echo "hoft hoft-science calibration guardian"
    else
        echo ${_SUMMARY_SYSTEMS_FAST}
    fi
}

get_slow_systems() {
    if [ -z "${_SUMMARY_SYSTEMS_SLOW}" ]; then
        local slowsystems="${_SUMMARY_SYSTEMS}"
        for fastsystem in `get_fast_systems`; do
            slowsystems=`echo ${slowsystems} | sed -e 's/'$fastsystem' //g'`
        done
        echo $slowsystems
    else
        echo ${_SUMMARY_SYSTEMS_SLOW}
    fi
}

get_config-file_and_priority_args() {
    local priority=""
    local _this_p=""
    local ini=""
    # parse requested systems
    local system=""
    local systems="$@"
    [ -z "$systems" ] && systems=${_SUMMARY_SYSTEMS}
    # get IFO if needed
    [ -z $IFO ] && set_site_environment
    # get defaults
    if [[ "G1 V1 C1" =~ ${IFO} &&
          -f ${_SUMMARY_CONFIG}/${ifo}/defaults.ini ]]; then
        config_file="--global-config ${_SUMMARY_CONFIG}/${ifo}/defaults.ini"
    else
        config_file="--global-config ${_SUMMARY_CONFIG}/defaults.ini"
    fi

    # loop over systems, finding config files
    for system in $systems; do
        local ini=""
        if [[ "H1 L1" =~ ${IFO} ]]; then
            # find common ini
            if [ -f ${_SUMMARY_CONFIG}/common/${system}.ini ]; then
                 ini="${_SUMMARY_CONFIG}/common/${system}.ini"
            fi
            # find IFO ini
            if [ -f ${_SUMMARY_CONFIG}/${ifo}/${ifo}${system}.ini ]; then
                if [ ! -z "${ini}" -a "${ini}" != " " ]; then
                    ini="${ini},${_SUMMARY_CONFIG}/${ifo}/${ifo}${system}.ini"
                else
                    ini="${_SUMMARY_CONFIG}/${ifo}/${ifo}${system}.ini"
                fi
            fi
        elif [[ "G1 V1 C1" =~ ${IFO} ]]; then
            if [ -f ${_SUMMARY_CONFIG}/${ifo}/${ifo}${system}.ini ]; then
                ini="${_SUMMARY_CONFIG}/${ifo}/${ifo}${system}.ini"
            fi
        else
            # find multi-IFO ini
            if [ -f ${_SUMMARY_CONFIG}/multi/${system}.ini ]; then
                ini="${_SUMMARY_CONFIG}/multi/${system}.ini"
            fi
        fi
        # set proirity
        if [[ "$system" =~ ^hoft.*|^guardian.* ]]; then
            _this_p=2
        elif [[ "$system" =~ ^sei*|^sus.* ]]; then
            _this_p=0
        else
            _this_p=1
        fi
        # if we found an INI file, append --config-file and --priority
        if [ ! -z "${ini}" -a "${ini}" != " " ]; then
            config_file="${config_file} --config-file ${ini}"
            priority="${priority} --priority ${_this_p}"
        fi
    done
    echo "${config_file} ${priority}"
}

find_all_systems() {
    local configdir=$1
    local _ifo=$2
    [ -z ${_ifo} ] && local _ifo=${ifo}
    echo `find ${configdir}/ -name ${_ifo}*ini -exec basename {} \; | cut -d. -f1 | cut -c3-`
}

# -- condor -------------------------------------------------------------------

get_condor_accounting_cmd() {
    local tag=$1
    [ -z $tag ] && local tag="${_SUMMARY_JOB}"
    if [[ -n "${_CONDOR_SLOT+x}" ]]; then
        CID=`get_condor_id $tag`
        if [[ $CID =~ ^[0-9]+$ ]]; then
            ACCOUNTING_TAG=`condor_q $CID -autof AccountingGroup`
            NPARTS=`echo ${ACCOUNTING_TAG} | tr "." " " | wc -w`
            ACCOUNTING_GROUP=`echo ${ACCOUNTING_TAG} | cut -d. -f -$((NPARTS-2))`
            ACCOUNTING_USER=`echo ${ACCOUNTING_TAG} | cut -d. -f $((NPARTS-1))-`
        else
            echo "Failed to parse cluster ID for SummaryPage manager" 1>&2
        fi
    fi
    if [[ -z ${ACCOUNTING_TAG} ]]; then
        if [ "${USER}" == "detchar" ] || [ "${USER}" == "40m" ]; then
            local mode="prod"
            [ -z $IFO ] && set_site_environment
            if [ ${IFO} == "C1" ]; then
                ACCOUNTING_USER="max.isi"
            else
                ACCOUNTING_USER="duncan.macleod"
            fi
        else
            local mode="dev"
            ACCOUNTING_USER=$USER
        fi
        ACCOUNTING_GROUP="ligo.$mode.o1.detchar.daily.summary"
    fi
    echo "--condor-command=accounting_group=${ACCOUNTING_GROUP} --condor-command=accounting_group_user=${ACCOUNTING_USER}"
}

get_condor_notify_cmd() {
    if [ -n "$_SUMMARY_CONDOR_NOTIFY" ]; then
        echo "--condor-command=notify_user=${CONDOR_NOTIFY} --condor-command=notification=Error"
    fi
}

get_condor_universe_cmd() {
    if [ -n "$_SUMMARY_CONDOR_UNIVERSE" ]; then
        echo "--universe ${_SUMMARY_CONDOR_UNIVERSE}"
    else
        echo "--universe local"
    fi
}

get_condor_timeout_cmd() {
    local timeout=$1
    [ -z $timeout ] && local timeout=12
    echo "--condor-timeout $timeout"
}

get_condor_arguments() {
    local condorcmd=""
    condorcmd="${condorcmd} `get_condor_notify_cmd`"
    condorcmd="${condorcmd} `get_condor_universe_cmd`"
    condorcmd="${condorcmd} `get_condor_accounting_cmd`"
    condorcmd="${condorcmd} `get_condor_timeout_cmd`"
    echo $condorcmd
}

get_condor_id() {
    local tag=$1
    condor_q -constraint \
        "Owner==\"${USER}\" && SummaryPageManager==\"${tag}\"" \
        -autof ClusterId
}

wait_for_dag_and_exit() {
    local dagfile=$1
    [ -z ${_SUMMARY_JOB} ] && local _SUMMARY_JOB=`basename ${dagfile%.*}`
    # wait for 10 seconds for DAG lock file to generate
    sleep 10
    # wait for lock file to disappear
    while [ -f ${dagfile}.lock ]; do
        sleep 30
    done
    echo "DAG has exited"
    # check for rescue DAG
    if [ -f ${dagfile}.rescue001 ]; then
        echoerr "Something broke, the rescue DAG was generated."
        return 1
    else
        # get parent ID
        CID=`get_condor_id ${_SUMMARY_JOB}`
        # reset condor shadow parameters to prevent annoying hold
        if [ -n "${CID}" ]; then
            echo "Resetting shadow parameters for condor id $CID..."
            condor_qedit ${CID} NumShadowExceptions 0
            condor_qedit ${CID} NumShadowStarts 0
        else
            echo "Failed to find condor id for persistent job ${_SUMMARY_JOB}" 1>&2
        fi
        # move DAG logfile out of the way to prevent continuous append
        mv ${dagfile}.dagman.out ${dagfile}.dagman.out.old
        echo "Summary page run complete!"
        return 0
    fi
}

# -- 40m ----------------------------------------------------------------------

update_40m_config() {
    local target=$1
    [ -z $target ] && local target=${_SUMMARY_CONFIG}/${ifo}
    local _user="controls"
    local _host="nodus.ligo.caltech.edu"
    #local _path="/cvs/cds/caltech/chans/GWsummaries"
    local _path="/users/public_html/detcharsummary/ConfigFiles"

    # pull from nodus if we can
    mkdir -p $target
    rsync --delete -r ${_user}@${_host}:${_path}/* ${target}/ || true

#     # push changes to git backup
#     if [[ -d "${target}/.git" ]]; then
#         cd ${target}
#         NOW=$(lalapps_tconvert now)
#         git add .
#         git commit -m "auto ${NOW}"
#         git push
#     fi

    # find all systems
    export _SUMMARY_SYSTEMS=`find_all_systems $target $ifo`
}

update_40m_medm() {
    local target=$1
    [ -z $target ] && local target="${_SUMMARY_OUT}/medm"
    local _user="controls"
    local _host="nodus.ligo.caltech.edu"
    local _path="/cvs/cds/caltech/users/public_html/detcharsummary/medm"

    echo ${target}
    # pull from nodus if we can
    mkdir -p $target
    rsync --delete -r ${_user}@${_host}:${_path}/* ${target}/ || true
}

# -- clean --------------------------------------------------------------------

clean_archive() {
    local day=$1
    local archivedir=${_SUMMARY_OUT}/day/${day}/archive
    # check directory
    if [ ! -d "${archivedir}" ]; then
        echo "No archive directory found for ${day}"
        return 2
    # allow manual preservation of archives
    elif [ -f "${archivedir}/KEEP" ]; then
        echo "Found KEEP, not deleting archives"
        return 1
    # otherwise, delete them. Delete them all!
    else
        rm -f ${archivedir}/*.hdf
        echo "Cleaned archive for ${day}"
    fi
}

clean_logs() {
    local ndays=$1
    [ -z $ndays ] && local ndays=7
    local logdir=${_SUMMARY_OUT}/logs
    _message=`find ${logdir}/ -type f -mtime +${ndays} -exec rm {} \;`
    if [ $? -eq 0 ]; then
        echo "Cleaned logs older than ${ndays} days"
    else
        echo ${_message}
        return 1
    fi
}
